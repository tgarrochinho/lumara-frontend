---
name: Documentation & Provider Addition Guide
status: open
created: 2025-10-14T03:28:21Z
updated: 2025-10-14T03:44:38Z
github: https://github.com/tgarrochinho/lumara-frontend/issues/22
depends_on: [25]
parallel: true
conflicts_with: []
---

# Task: Documentation & Provider Addition Guide

## Description
Create comprehensive documentation for the AI system including architecture overview, API documentation, and step-by-step guide for adding new AI providers (Gemini API, LM Studio, OpenAI, Claude).

## Acceptance Criteria
- [ ] README.md for AI system created
- [ ] Architecture decision records (ADRs) documented
- [ ] API documentation complete
- [ ] Provider addition guide with examples
- [ ] Troubleshooting guide created
- [ ] Code examples for all major features
- [ ] JSDoc comments on all public APIs

## Technical Details

### Files to Create
```
docs/ai/
├── README.md                # Overview
├── architecture.md          # Architecture decisions
├── provider-guide.md        # Adding new providers
├── troubleshooting.md       # Common issues
└── examples/
    ├── basic-usage.md
    ├── adding-provider.md
    └── custom-embeddings.md
```

### Implementation

1. **AI System README** (`docs/ai/README.md`)
```markdown
# Lumara AI System

## Overview

Lumara's AI system is built on a **provider abstraction pattern** that supports multiple AI providers while starting with Chrome's built-in Gemini Nano.

### Key Features

- **Local-first by default** - Chrome AI runs on-device
- **Privacy-preserving** - No data sent to servers
- **Extensible** - Easy to add new providers
- **Zero-cost** - Free tier uses browser AI
- **Performant** - <100ms embeddings, <2s chat

### Architecture

```
User Input
    ↓
AI Provider Registry
    ├→ Chrome AI (Gemini Nano)      [v1]
    ├→ Gemini API                   [v2]
    ├→ LM Studio                    [v3]
    ├→ OpenAI                       [v3]
    └→ Claude                       [v3]
```

### Quick Start

\`\`\`typescript
import { selectProvider } from '@/lib/ai/registry';
import { generateEmbedding } from '@/lib/ai/embeddings/transformers';

// Get AI provider
const provider = await selectProvider('chrome-ai');

// Chat
const response = await provider.chat('Hello!');

// Generate embedding
const embedding = await generateEmbedding('Some text');
\`\`\`

## Components

### Providers
- `ChromeAIProvider` - Chrome built-in AI (Gemini Nano)
- `GeminiAPIProvider` - Google Gemini API (v2)
- `LMStudioProvider` - Local models via LM Studio (v3)
- `OpenAIProvider` - OpenAI API (v3)
- `ClaudeProvider` - Anthropic Claude (v3)

### Embeddings
- Browser-based via Transformers.js
- MiniLM-L6-v2 model (384 dimensions)
- Aggressive caching strategy

### Utilities
- Cosine similarity
- Contradiction detection
- Health monitoring
- Error handling

## Configuration

### Origin Trial Token

Required for Chrome AI (Gemini Nano):

\`\`\`html
<!-- index.html -->
<meta http-equiv="origin-trial" content="YOUR_TOKEN_HERE">
\`\`\`

Register at: https://developer.chrome.com/origintrials

### Provider Selection

\`\`\`typescript
// Auto-select best available
const provider = await selectProvider();

// Prefer specific provider
const provider = await selectProvider('chrome-ai');
\`\`\`

## Performance

| Operation | Target | Typical |
|-----------|--------|---------|
| First setup | <30s | ~20s |
| Subsequent load | <1s | ~500ms |
| Embedding | <100ms | ~50ms |
| Chat | <2s | ~1s |
| Similarity (1K) | <50ms | ~20ms |

## Troubleshooting

See [troubleshooting.md](./troubleshooting.md)

## Adding Providers

See [provider-guide.md](./provider-guide.md)
```

2. **Provider Addition Guide** (`docs/ai/provider-guide.md`)
```markdown
# Adding New AI Providers

This guide shows how to add new AI providers to Lumara.

## Overview

Adding a provider takes ~2 hours and requires 3 files:

1. Provider implementation (`src/lib/ai/providers/your-provider.ts`)
2. Registry entry (`src/lib/ai/registry.ts`)
3. Settings UI option (`src/components/settings/AISettings.tsx`)

## Step-by-Step Guide

### Step 1: Implement AIProvider Interface

\`\`\`typescript
// src/lib/ai/providers/gemini-api.ts
import { BaseProvider } from './base';
import { ProviderConfig, ProviderHealth } from '../types';

export class GeminiAPIProvider extends BaseProvider {
  name = 'Google Gemini API';
  type = 'cloud' as const;
  requiresApiKey = true;

  capabilities = {
    chat: true,
    embeddings: true,
    streaming: false,
    multimodal: false,
  };

  private apiKey: string | null = null;

  async initialize(config?: ProviderConfig): Promise<void> {
    if (!config?.apiKey) {
      throw new Error('API key required for Gemini API');
    }

    this.apiKey = config.apiKey;
    this.initialized = true;
  }

  async chat(message: string, context?: string[]): Promise<string> {
    const response = await fetch(
      'https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent',
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          contents: [{ parts: [{ text: message }] }],
        }),
      }
    );

    const data = await response.json();
    return data.candidates[0].content.parts[0].text;
  }

  async embed(text: string): Promise<number[]> {
    const response = await fetch(
      'https://generativelanguage.googleapis.com/v1/models/embedding-001:embedContent',
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          content: { parts: [{ text }] },
        }),
      }
    );

    const data = await response.json();
    return data.embedding.values;
  }

  async healthCheck(): Promise<ProviderHealth> {
    try {
      await this.chat('test');
      return {
        available: true,
        status: 'ready',
        lastChecked: new Date(),
      };
    } catch (error) {
      return {
        available: false,
        status: 'error',
        message: error.message,
        lastChecked: new Date(),
      };
    }
  }

  async dispose(): Promise<void> {
    this.apiKey = null;
    this.initialized = false;
  }
}
\`\`\`

### Step 2: Register Provider

\`\`\`typescript
// src/lib/ai/registry.ts
import { GeminiAPIProvider } from './providers/gemini-api';

export const providerRegistry = {
  'chrome-ai': ChromeAIProvider,
  'gemini': GeminiAPIProvider,  // ← Add here
  // ... more providers
};
\`\`\`

### Step 3: Add to Settings UI

\`\`\`typescript
// src/components/settings/AISettings.tsx
<ProviderSelector
  options={[
    { value: 'chrome-ai', label: 'Chrome AI (Free)' },
    { value: 'gemini', label: 'Google Gemini' },  // ← Add here
    { value: 'openai', label: 'OpenAI' },
  ]}
/>
\`\`\`

### Step 4: Add API Key Management (if needed)

\`\`\`typescript
// src/components/settings/APIKeyManager.tsx
export function APIKeyManager() {
  const [geminiKey, setGeminiKey] = useState('');

  const saveKeys = () => {
    localStorage.setItem('gemini-api-key', geminiKey);
  };

  return (
    <div>
      <input
        type="password"
        value={geminiKey}
        onChange={(e) => setGeminiKey(e.target.value)}
        placeholder="Gemini API Key"
      />
      <button onClick={saveKeys}>Save</button>
    </div>
  );
}
\`\`\`

## Testing Your Provider

\`\`\`typescript
// src/lib/ai/__tests__/gemini-provider.test.ts
import { GeminiAPIProvider } from '../providers/gemini-api';

describe('GeminiAPIProvider', () => {
  it('initializes with API key', async () => {
    const provider = new GeminiAPIProvider();
    await provider.initialize({ apiKey: 'test-key' });

    expect(provider.isReady()).toBe(true);
  });

  it('generates chat responses', async () => {
    const provider = new GeminiAPIProvider();
    await provider.initialize({ apiKey: process.env.GEMINI_API_KEY });

    const response = await provider.chat('Hello');
    expect(response).toBeTruthy();
  });
});
\`\`\`

## Examples

See `docs/ai/examples/` for complete provider implementations:

- Gemini API
- LM Studio
- OpenAI
- Claude

## Provider Checklist

- [ ] Implements AIProvider interface
- [ ] Extends BaseProvider
- [ ] Declares capabilities correctly
- [ ] Has proper error handling
- [ ] Includes health check
- [ ] Registered in registry
- [ ] Added to settings UI
- [ ] Unit tests written
- [ ] Documentation updated

That's it! Your new provider is ready to use.
```

3. **JSDoc Comments** (Add to all files)
```typescript
/**
 * AI Provider abstraction for Lumara.
 *
 * Supports multiple AI providers (Chrome AI, Gemini, OpenAI, etc.)
 * with a unified interface.
 *
 * @example
 * \`\`\`typescript
 * const provider = await selectProvider('chrome-ai');
 * const response = await provider.chat('Hello!');
 * \`\`\`
 *
 * @module ai
 */

/**
 * Interface that all AI providers must implement.
 *
 * @interface AIProvider
 */
export interface AIProvider {
  /**
   * Provider name (e.g., "Chrome AI", "Gemini API")
   */
  readonly name: string;

  /**
   * Provider type: local (on-device), cloud (API), hosted (Lumara servers)
   */
  readonly type: 'local' | 'cloud' | 'hosted';

  /**
   * Whether this provider requires an API key
   */
  readonly requiresApiKey: boolean;

  /**
   * Provider capabilities
   */
  capabilities: AICapabilities;

  /**
   * Generate chat response
   *
   * @param message - User message
   * @param context - Optional context from previous messages
   * @returns AI-generated response
   *
   * @throws {ProviderUnavailableError} If provider not initialized
   * @throws {NetworkError} If API call fails
   */
  chat(message: string, context?: string[]): Promise<string>;

  /**
   * Generate semantic embedding for text
   *
   * @param text - Input text
   * @returns Embedding vector (typically 384 or 768 dimensions)
   *
   * @throws {EmbeddingError} If embedding generation fails
   */
  embed(text: string): Promise<number[]>;

  /**
   * Initialize provider with configuration
   *
   * @param config - Provider configuration (API keys, etc.)
   *
   * @throws {ProviderUnavailableError} If provider cannot be initialized
   */
  initialize(config?: ProviderConfig): Promise<void>;

  /**
   * Check provider health and availability
   *
   * @returns Health status
   */
  healthCheck(): Promise<ProviderHealth>;

  /**
   * Clean up resources
   */
  dispose(): Promise<void>;
}
```

4. **Troubleshooting Guide** (`docs/ai/troubleshooting.md`)
```markdown
# AI System Troubleshooting

## Common Issues

### Chrome AI Not Available

**Error:** "Chrome AI not available"

**Solution:**
1. Use Chrome Canary or Chrome Dev (not Stable)
2. Enable flag: `chrome://flags/#optimization-guide-on-device-model`
3. Enable flag: `chrome://flags/#prompt-api-for-gemini-nano`
4. Restart Chrome
5. Check `chrome://components` for "Optimization Guide"

### Model Download Fails

**Error:** "Failed to load model"

**Solution:**
1. Check internet connection
2. Clear browser cache
3. Check available disk space (need ~25MB)
4. Try again in a few minutes

### Embeddings Slow

**Issue:** Embeddings take >100ms

**Solution:**
1. Check if model cached (second run should be faster)
2. Close other tabs (reduce memory pressure)
3. Check CPU usage
4. Consider using Web Worker (advanced)

### Memory Usage High

**Issue:** Browser using >500MB

**Solution:**
1. Clear embedding cache periodically
2. Limit number of memories loaded
3. Use virtual scrolling for large lists
4. Monitor with browser DevTools

## Debug Mode

Enable detailed logging:

\`\`\`typescript
localStorage.setItem('lumara-debug-ai', 'true');
\`\`\`

## Performance Monitoring

Check performance stats:

\`\`\`typescript
import { performanceMonitor } from '@/lib/ai/performance';

console.log(performanceMonitor.getAllStats());
\`\`\`

## Getting Help

1. Check [GitHub Issues](https://github.com/yourusername/lumara/issues)
2. Search [Documentation](./README.md)
3. Join [Discord](https://discord.gg/lumara)
```

## Dependencies
- [ ] Task 001 complete for API documentation
- [ ] All tasks for comprehensive guide

## Effort Estimate
- **Size:** M (Medium)
- **Hours:** 12-16 hours
- **Parallel:** Yes - Can start early

## Definition of Done
- [ ] All documentation files created
- [ ] Provider guide tested (someone else can follow it)
- [ ] JSDoc comments on all public APIs
- [ ] Code examples validated
- [ ] Troubleshooting guide comprehensive
- [ ] Architecture decisions documented
- [ ] README.md clear and complete
